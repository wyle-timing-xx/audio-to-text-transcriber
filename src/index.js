// src/index.js
import { createClient, LiveTranscriptionEvents } from '@deepgram/sdk';
import { spawn } from 'child_process';
import { createWriteStream, mkdirSync, appendFileSync } from 'fs';
import { dirname } from 'path';
import dotenv from 'dotenv';
import fetch from 'node-fetch'; // npm i node-fetch@2 (or use global fetch in newer Node)
import OpenAI from 'openai'; // ä½¿ç”¨ OpenAI SDK è°ƒç”¨ Deepseek API
import { pipeline } from 'stream';
import { promisify } from 'util';

// åŠ è½½ç¯å¢ƒå˜é‡
dotenv.config();

// é…ç½®é¡¹
const CONFIG = {
  deepgramApiKey: process.env.DEEPGRAM_API_KEY,
  audioDevice: process.env.AUDIO_DEVICE || ':1',
  language: process.env.LANGUAGE || 'en',
  model: process.env.MODEL || 'nova-2',
  smartFormat: process.env.SMART_FORMAT === 'true',
  punctuate: process.env.PUNCTUATE === 'true',
  outputFile: process.env.OUTPUT_FILE || 'transcripts/output.txt',
  qaOutputFile: process.env.QA_OUTPUT_FILE || 'transcripts/qa_output.txt',
  saveToFile: process.env.SAVE_TO_FILE !== 'false',
  logToConsole: process.env.LOG_TO_CONSOLE !== 'false',
  // AI é…ç½®
  aiProvider: (process.env.AI_PROVIDER || 'openai').toLowerCase(), // openai | claude | deepseek
  openaiApiKey: process.env.OPENAI_API_KEY,
  claudeApiKey: process.env.CLAUDE_API_KEY,
  deepseekApiKey: process.env.DEEPSEEK_API_KEY,
  deepseekEndpoint: process.env.DEEPSEEK_ENDPOINT || 'https://api.deepseek.com', // é»˜è®¤ä½¿ç”¨å®˜æ–¹ API åœ°å€
  // AI æ¨¡å‹é…ç½®
  openaiModel: process.env.OPENAI_MODEL || 'gpt-4o-mini',
  claudeModel: process.env.CLAUDE_MODEL || 'claude-3-opus-20240229',
  deepseekModel: process.env.DEEPSEEK_MODEL || 'deepseek-chat',
  // prompt / behavior
  aiSystemPrompt: process.env.AI_SYSTEM_PROMPT || `ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½é—®ç­”åŠ©æ‰‹ã€‚å½“å‰å¯¹è¯ä¸º"è¯­éŸ³é—®ç­”"ã€‚è¦æ±‚ï¼š
1) è¿™æ˜¯ç”¨æˆ·è¯´å‡ºçš„è¯­éŸ³è½¬ä¸ºæ–‡å­—åçš„å†…å®¹ï¼Œåˆ¤å®šç”¨æˆ·æ˜¯å¦å·²ç»é—®å®Œï¼ˆå¯ä¾æ®åœé¡¿/æ ‡ç‚¹ï¼‰ï¼Œå¦‚æœæœªé—®å®Œè¯·ç­‰å¾…æ›´å¤šè¾“å…¥ï¼›å¦‚æœå·²é—®å®Œè¯·ç›´æ¥ä»¥å›ç­”è€…è§’è‰²ç»™å‡ºå›ç­”ã€‚
2) å›ç­”è¦ç®€æ´ã€å‡†ç¡®ï¼Œå¿…è¦æ—¶ç»™å‡ºæ­¥éª¤/æç¤ºã€‚
3) å¦‚æœç”¨æˆ·æœ‰åç»­é—®é¢˜ï¼Œè¯·åœ¨ç»“å°¾æç¤ºç”¨æˆ·å¯ä»¥ç»§ç»­è¿½é—®ã€‚
`,
  // é™é»˜æ£€æµ‹ï¼ˆæ¯«ç§’ï¼‰ â€” åœ¨æ— æ–°è½¬å½•ç‰‡æ®µçš„æƒ…å†µä¸‹åˆ¤å®šç”¨æˆ·å·²ç»“æŸä¸€å¥è¯
  silenceTimeoutMs: parseInt(process.env.SILENCE_TIMEOUT_MS || '1500', 10),
  // éƒ¨åˆ†ä¸ŠæŠ¥ç­–ç•¥ï¼šæ¯å½“æ¥æ”¶åˆ°ä¸€ä¸ª transcript chunk å°±å‘é€åˆ° AI çš„"è®°å½•"æ¥å£ï¼›æœ€ç»ˆåœ¨ silenceTimeout è§¦å‘å®Œæ•´æé—®
  partialSend: process.env.PARTIAL_SEND !== 'false',
  // ä¸­æ–­æ£€æµ‹æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰- åœ¨ AI å›ç­”è¿‡ç¨‹ä¸­ï¼Œæ£€æµ‹åˆ°æ–°çš„éŸ³é¢‘è¾“å…¥åï¼Œç­‰å¾…æ­¤æ—¶é—´ï¼Œè‹¥æ— æ›´å¤šè¾“å…¥åˆ™ä¸­æ–­ AI
  interruptionDetectionMs: parseInt(process.env.INTERRUPTION_DETECTION_MS || '300', 10),
  // æ˜¯å¦å…è®¸ä¸­æ–­ AI å›ç­”
  allowInterruption: process.env.ALLOW_INTERRUPTION !== 'false'
};

// éªŒè¯å¿…éœ€é…ç½®
if (!CONFIG.deepgramApiKey) {
  console.error('âŒ Error: DEEPGRAM_API_KEY is not set in .env file');
  process.exit(1);
}

if (CONFIG.aiProvider === 'openai' && !CONFIG.openaiApiKey) {
  console.error('âŒ Error: OPENAI_API_KEY required for OpenAI provider');
  process.exit(1);
}
if (CONFIG.aiProvider === 'claude' && !CONFIG.claudeApiKey) {
  console.error('âŒ Error: CLAUDE_API_KEY required for Claude provider');
  process.exit(1);
}
if (CONFIG.aiProvider === 'deepseek' && !CONFIG.deepseekApiKey) {
  console.error('âŒ Error: DEEPSEEK_API_KEY required for Deepseek provider');
  process.exit(1);
}

// åˆ›å»ºè¾“å‡ºç›®å½•
if (CONFIG.saveToFile) {
  mkdirSync(dirname(CONFIG.outputFile), { recursive: true });
  mkdirSync(dirname(CONFIG.qaOutputFile), { recursive: true });
}

// åˆ›å»ºå¯ä¸­æ–­æ§åˆ¶çš„ AbortController
class InterruptibleController {
  constructor() {
    this.controller = new AbortController();
    this.interrupted = false;
  }

  abort() {
    this.interrupted = true;
    this.controller.abort();
  }

  get signal() {
    return this.controller.signal;
  }

  isInterrupted() {
    return this.interrupted;
  }

  reset() {
    this.controller = new AbortController();
    this.interrupted = false;
  }
}

class AIManager {
  constructor(config) {
    this.config = config;
    this.provider = config.aiProvider;
    this.buffer = ''; // å½“å‰é—®é¢˜ç¼“å†²ï¼ˆå¢é‡æ‹¼æ¥ï¼‰
    this.conversationHistory = []; // [{role, content, timestamp}]
    this.silenceTimer = null;
    this.isProcessing = false; // æ˜¯å¦æ­£åœ¨ç­‰å¾… AI æœ€ç»ˆå›ç­”
    this.currentController = new InterruptibleController(); // å¯ä¸­æ–­æ§åˆ¶å™¨
    this.interruptionTimer = null; // ä¸­æ–­æ£€æµ‹è®¡æ—¶å™¨
    this.lastUserInputTime = Date.now(); // ä¸Šæ¬¡ç”¨æˆ·è¾“å…¥æ—¶é—´
    this.hasNewUserInput = false; // æ˜¯å¦æœ‰æ–°çš„ç”¨æˆ·è¾“å…¥
    
    // åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯ (ç”¨äº Deepseek å’Œ OpenAI)
    if (this.provider === 'openai') {
      this.openai = new OpenAI({
        apiKey: config.openaiApiKey
      });
    } else if (this.provider === 'deepseek') {
      this.openai = new OpenAI({
        baseURL: config.deepseekEndpoint,
        apiKey: config.deepseekApiKey
      });
    }
  }

  // å°† fragment æ·»åŠ åˆ° bufferï¼Œå¹¶ï¼ˆå¯é€‰ï¼‰åš partial sendï¼ˆè®°å½•/ä¸Šä¸‹æ–‡ï¼‰
  async pushTranscriptFragment(fragment) {
    const text = fragment.trim();
    if (!text) return;
    const ts = new Date().toISOString();
    this.buffer += (this.buffer ? ' ' : '') + text;

    // è®°å½•å¢é‡åˆ°ä¼šè¯å†å²ï¼ˆä½†æ ‡æ³¨ä¸º partialï¼‰
    this.conversationHistory.push({ role: 'user_partial', content: text, timestamp: ts });

    // æ›´æ–°æœ€åç”¨æˆ·è¾“å…¥æ—¶é—´
    this.lastUserInputTime = Date.now();
    this.hasNewUserInput = true;

    // å¦‚æœå…è®¸ä¸­æ–­ï¼Œä¸” AI æ­£åœ¨å›ç­”ï¼Œåˆ™å‡†å¤‡ä¸­æ–­
    if (this.config.allowInterruption && this.isProcessing) {
      this._prepareInterruption();
    }

    if (this.config.partialSend) {
      // è½»é‡åŒ–ä¸ŠæŠ¥ï¼šå¯é€‰æ‹©æŠŠ partial å‘é€ç»™ AI åšä¸Šä¸‹æ–‡è®°å½•ï¼ˆéè¯·æ±‚ç­”æ¡ˆï¼‰
      // æˆ‘ä»¬å®ç°ä¸ºä¸€ä¸ª "note" call to provider â€” provider å¯ä»¥å¿½ç•¥æˆ–è®°å½•
      try {
        await this._notifyProviderOfPartial(text);
      } catch (e) {
        // ä¸é˜»å¡ä¸»æµç¨‹
        console.error('âš ï¸ Partial send failed:', e.message || e);
      }
    }

    // é‡ç½®é™é»˜è®¡æ—¶å™¨
    this._resetSilenceTimer();
  }

  // å‡†å¤‡ä¸­æ–­ AI å›ç­”
  _prepareInterruption() {
    // æ¸…é™¤ä¹‹å‰çš„ä¸­æ–­è®¡æ—¶å™¨
    if (this.interruptionTimer) {
      clearTimeout(this.interruptionTimer);
    }

    // è®¾ç½®æ–°çš„ä¸­æ–­è®¡æ—¶å™¨
    this.interruptionTimer = setTimeout(() => {
      // å¦‚æœè®¡æ—¶å™¨è§¦å‘ï¼Œä¸”åœ¨æ£€æµ‹æ—¶é—´å†…æ²¡æœ‰æ–°çš„è¾“å…¥ï¼Œåˆ™æ‰§è¡Œä¸­æ–­
      if (Date.now() - this.lastUserInputTime >= this.config.interruptionDetectionMs) {
        this._interruptAIResponse();
      }
    }, this.config.interruptionDetectionMs);
  }

  // ä¸­æ–­ AI å›ç­”
  _interruptAIResponse() {
    if (!this.isProcessing || !this.hasNewUserInput) return;
    
    console.log("\n\nğŸ”„ æ£€æµ‹åˆ°æ–°è¾“å…¥ï¼Œä¸­æ–­å½“å‰ AI å›ç­”...\n");
    if (this.config.saveToFile) {
      appendFileSync(this.config.qaOutputFile, "\n\n[ä¸­æ–­ï¼šæ£€æµ‹åˆ°æ–°è¾“å…¥]\n\n");
    }

    // ä¸­æ–­å½“å‰çš„ AI å“åº”
    this.currentController.abort();
    
    // é‡ç½®çŠ¶æ€ä»¥å‡†å¤‡å¤„ç†æ–°çš„ç”¨æˆ·è¾“å…¥
    this.hasNewUserInput = false;
    // æ­¤æ—¶ä¸é‡ç½® isProcessingï¼Œå› ä¸º _onSilenceTimeout ä¸­ä¼šç­‰å¾…é™é»˜åå†å¤„ç†æ–°çš„é—®é¢˜
  }

  _resetSilenceTimer() {
    if (this.silenceTimer) clearTimeout(this.silenceTimer);
    this.silenceTimer = setTimeout(() => this._onSilenceTimeout(), this.config.silenceTimeoutMs);
  }

  async _onSilenceTimeout() {
    // è¶…è¿‡é™é»˜é˜ˆå€¼ï¼Œè®¤å®šä¸€å¥"ç”¨æˆ·è¯"ç»“æŸ â†’ è§¦å‘æœ€ç»ˆé—®ç­”
    if (!this.buffer) {
      return;
    }
    
    // å¦‚æœå½“å‰æœ‰ AI æ­£åœ¨å›ç­”ä¸”è¢«ä¸­æ–­äº†ï¼Œç­‰å¾…ä¸­æ–­å®Œæˆ
    if (this.isProcessing && this.currentController.isInterrupted()) {
      // ç¨å¾®å»¶è¿Ÿä¸€ä¸‹ï¼Œç­‰å¾…ä¸­æ–­å®Œæˆ
      setTimeout(() => this._onSilenceTimeout(), 100);
      return;
    }
    
    // å¦‚æœå½“å‰æœ‰ AI æ­£åœ¨å›ç­”ä½†æ²¡æœ‰è¢«ä¸­æ–­ï¼Œåˆ™ä¸å¤„ç†æ–°çš„é—®é¢˜
    if (this.isProcessing && !this.currentController.isInterrupted()) {
      this.buffer = '';
      return;
    }
    
    const question = this.buffer.trim();
    this.buffer = '';
    
    // add final user message
    this.conversationHistory.push({ role: 'user', content: question, timestamp: new Date().toISOString() });
    
    // call AI for answer
    try {
      this.isProcessing = true;
      this.currentController.reset(); // é‡ç½®æ§åˆ¶å™¨ä¸ºæ–°çš„å›ç­”åšå‡†å¤‡
      this.hasNewUserInput = false; // é‡ç½®æ–°è¾“å…¥æ ‡å¿—
      await this.getAnswerForQuestion(question);
    } catch (error) {
      if (error.name === 'AbortError') {
        console.log("AI å›ç­”è¢«ä¸­æ–­");
      } else {
        console.error("AI å›ç­”å‡ºé”™:", error);
      }
    } finally {
      this.isProcessing = false;
    }
  }

  // å°†éƒ¨åˆ†ç‰‡æ®µé€šçŸ¥ providerï¼ˆéå¼ºåˆ¶ï¼‰
  async _notifyProviderOfPartial(text) {
    // For simplicity we call provider with a "log" endpoint if available.
    // Implementations can be no-op for providers that don't support it.
    if (this.provider === 'openai') {
      // noop (we rely on final call)
      return;
    } else if (this.provider === 'claude') {
      return;
    } else if (this.provider === 'deepseek') {
      // noop
      return;
    }
  }

  // è§¦å‘è¯·æ±‚ AI è·å–ç­”æ¡ˆï¼ˆæœ€ç»ˆå›ç­”ï¼‰ï¼Œå¹¶æµå¼å°†ç­”æ¡ˆè¾“å‡ºåˆ°æ§åˆ¶å° + æ–‡ä»¶
  async getAnswerForQuestion(question) {
    const startTs = new Date().toISOString();
    const systemPrompt = this.config.aiSystemPrompt;

    // Build messages (conversation history + current question)
    const messages = [
      { role: 'system', content: systemPrompt },
      // include last N user messages for context (å¯æ”¹)
    ];
    // include some recent history
    const recent = this.conversationHistory.slice(-10).filter(h => {
      // è¿‡æ»¤æ‰ partial è®°å½•ï¼Œåªä¿ç•™å®Œæ•´å¯¹è¯
      return h.role !== 'user_partial';
    });
    messages.push(...recent);
    messages.push({ role: 'user', content: question });

    // Save QA header in file
    const qaHeader = `\n\n=== QA Session Started: ${startTs} (provider=${this.provider}) ===\nQ: ${question}\n`;
    if (this.config.saveToFile) appendFileSync(this.config.qaOutputFile, qaHeader);

    // Dispatch to provider
    let partialAnswer = '';
    try {
      // ç»Ÿä¸€ä½¿ç”¨ streamCompletion æ–¹æ³•å¤„ç†æ‰€æœ‰ AI providerï¼Œå¹¶ä¼ å…¥ä¸­æ–­æ§åˆ¶å™¨
      partialAnswer = await this._streamCompletion(messages, this.currentController);
    } catch (error) {
      if (error.name === 'AbortError') {
        // æ­£å¸¸ä¸­æ–­ï¼Œè®°å½•ä¸­æ–­ä¿¡æ¯
        if (this.config.saveToFile) {
          appendFileSync(this.config.qaOutputFile, `\n[å›ç­”è¢«ä¸­æ–­]\n`);
        }
        // å°†ä¸­æ–­çš„å›ç­”æ·»åŠ åˆ°ä¼šè¯å†å²
        this.conversationHistory.push({
          role: 'assistant',
          content: `${partialAnswer} [å›ç­”è¢«ä¸­æ–­]`,
          timestamp: new Date().toISOString(),
          interrupted: true
        });
        return partialAnswer;
      } else {
        // å…¶ä»–é”™è¯¯
        console.error(`âŒ ${this.provider.toUpperCase()} error:`, error.message);
        if (this.config.saveToFile) {
          appendFileSync(this.config.qaOutputFile, `${this.provider.toUpperCase()} error: ${error.message}\n`);
        }
      }
    }

    if (!this.currentController.isInterrupted()) {
      this.conversationHistory.push({
        role: 'assistant',
        content: partialAnswer,
        timestamp: new Date().toISOString()
      });
      
      const endTs = new Date().toISOString();
      if (this.config.saveToFile) appendFileSync(this.config.qaOutputFile, `\n=== QA Session Ended: ${endTs} ===\n`);
    }
    
    return partialAnswer;
  }

  // ç»Ÿä¸€çš„æµå¼è°ƒç”¨æ–¹æ³•ï¼Œæ ¹æ® provider ç±»å‹è°ƒç”¨ä¸åŒçš„å®ç°
  async _streamCompletion(messages, controller) {
    switch (this.provider) {
      case 'openai':
        return await this._streamOpenAI(messages, controller);
      case 'claude':
        return await this._streamClaude(messages, controller);
      case 'deepseek':
        return await this._streamDeepseekWithSDK(messages, controller);
      default:
        throw new Error(`Unknown AI provider: ${this.provider}`);
    }
  }

  // å¤„ç† Reader æµçš„é€šç”¨æ–¹æ³•ï¼Œæ·»åŠ ä¸­æ–­æ”¯æŒ
  async _processStream(reader, textDecoder, parseChunk, controller) {
    let done = false;
    let partialAnswer = '';
    
    try {
      while (!done) {
        // æ£€æŸ¥æ˜¯å¦è¢«ä¸­æ–­
        if (controller.isInterrupted()) {
          reader.cancel();
          throw new DOMException('Stream processing aborted', 'AbortError');
        }
        
        const { value, done: readerDone } = await reader.read();
        done = readerDone;
        
        if (value) {
          const chunk = textDecoder.decode(value, { stream: true });
          const tokens = parseChunk(chunk);
          
          for (const token of tokens) {
            // æ¯å¤„ç†ä¸€ä¸ª token ä¹Ÿæ£€æŸ¥æ˜¯å¦è¢«ä¸­æ–­
            if (controller.isInterrupted()) {
              reader.cancel();
              throw new DOMException('Stream processing aborted', 'AbortError');
            }
            
            if (token) {
              process.stdout.write(token);
              partialAnswer += token;
              if (this.config.saveToFile) appendFileSync(this.config.qaOutputFile, token);
            }
          }
        }
      }
    } catch (error) {
      if (error.name === 'AbortError') {
        throw error; // é‡æ–°æŠ›å‡ºä¸­æ–­é”™è¯¯
      }
      console.error('Stream processing error:', error);
    }
    
    if (this.config.logToConsole && !controller.isInterrupted()) console.log('\n');
    return partialAnswer;
  }

  // OpenAI æµå¼å®ç° (ä½¿ç”¨ v1 completions API)ï¼Œæ·»åŠ ä¸­æ–­æ”¯æŒ
  async _streamOpenAI(messages, controller) {
    const apiKey = this.config.openaiApiKey;
    const url = 'https://api.openai.com/v1/chat/completions';

    // è¯·æ±‚ stream=true å¹¶è§£æ SSE æµ
    const body = {
      model: this.config.openaiModel,
      messages: messages,
      temperature: 0.2,
      stream: true
    };

    const res = await fetch(url, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(body),
      signal: controller.signal
    });

    if (!res.ok) {
      const text = await res.text();
      throw new Error(`HTTP error ${res.status}: ${text}`);
    }

    // ä½¿ç”¨é€šç”¨æµå¤„ç†æ–¹æ³•
    const reader = res.body.getReader();
    const decoder = new TextDecoder('utf-8');
    
    return await this._processStream(reader, decoder, (chunk) => {
      // OpenAI æµè§£æ
      const tokens = [];
      const lines = chunk.split(/\r?\n/).filter(l => l.trim().length > 0);
      
      for (const line of lines) {
        if (line.startsWith('data: ')) {
          const payload = line.replace(/^data: /, '');
          if (payload === '[DONE]') continue;
          
          try {
            const parsed = JSON.parse(payload);
            const token = parsed.choices?.[0]?.delta?.content || '';
            if (token) tokens.push(token);
          } catch (e) {
            // å¿½ç•¥ JSON è§£æé”™è¯¯
          }
        }
      }
      
      return tokens;
    }, controller);
  }

  // Claude æµå¼å®ç°ï¼Œæ·»åŠ ä¸­æ–­æ”¯æŒ
  async _streamClaude(messages, controller) {
    const apiKey = this.config.claudeApiKey;
    
    // æ„å»º API è¯·æ±‚
    // æ³¨æ„ï¼šClaude API ä»æ—§ç‰ˆçš„ v1/complete å·²æ›´æ–°åˆ° v1/messages
    const url = 'https://api.anthropic.com/v1/messages';
    
    // è½¬æ¢æ¶ˆæ¯æ ¼å¼ä¸º Claude æ ¼å¼
    const systemPrompt = messages.find(m => m.role === 'system')?.content || '';
    const userMessages = messages.filter(m => m.role !== 'system');
    
    const body = {
      model: this.config.claudeModel,
      system: systemPrompt,
      messages: userMessages.map(m => ({
        role: m.role,
        content: m.content
      })),
      max_tokens: 800,
      temperature: 0.2,
      stream: true
    };

    const res = await fetch(url, {
      method: 'POST',
      headers: {
        'x-api-key': apiKey,
        'anthropic-version': '2023-06-01',
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(body),
      signal: controller.signal
    });

    if (!res.ok) {
      const text = await res.text();
      throw new Error(`HTTP error ${res.status}: ${text}`);
    }

    // ä½¿ç”¨é€šç”¨æµå¤„ç†æ–¹æ³•
    const reader = res.body.getReader();
    const decoder = new TextDecoder('utf-8');
    
    return await this._processStream(reader, decoder, (chunk) => {
      // Claude æµè§£æ
      const tokens = [];
      const lines = chunk.split(/\r?\n/).filter(l => l.trim().length > 0);
      
      for (const line of lines) {
        if (line.startsWith('data: ')) {
          const payload = line.replace(/^data: /, '');
          if (payload === '[DONE]') continue;
          
          try {
            const parsed = JSON.parse(payload);
            // æ–°ç‰ˆ Claude API åœ¨ delta.text ä¸­è¿”å› token
            const token = parsed.delta?.text || '';
            if (token) tokens.push(token);
          } catch (e) {
            // é JSON è¡Œï¼Œå¯èƒ½æ˜¯æ™®é€šæ–‡æœ¬ï¼ˆæ—§ç‰ˆAPIï¼‰
            if (line !== 'data: [DONE]') tokens.push(line);
          }
        }
      }
      
      return tokens;
    }, controller);
  }

  // ä½¿ç”¨ OpenAI SDK è°ƒç”¨ Deepseek APIï¼ˆæµå¼ï¼‰ï¼Œæ·»åŠ ä¸­æ–­æ”¯æŒ
  async _streamDeepseekWithSDK(messages, controller) {
    try {
      // ä½¿ç”¨ OpenAI SDK åˆ›å»ºæµå¼å¯¹è¯å®Œæˆ
      const stream = await this.openai.chat.completions.create({
        model: this.config.deepseekModel,
        messages: messages.map(msg => ({
          role: msg.role,
          content: msg.content
        })),
        stream: true,
        temperature: 0.2
      }, { signal: controller.signal });

      let fullText = '';

      // å¤„ç†æµå¼å“åº”
      for await (const chunk of stream) {
        // æ£€æŸ¥æ˜¯å¦è¢«ä¸­æ–­
        if (controller.isInterrupted()) {
          throw new DOMException('Stream processing aborted', 'AbortError');
        }
        
        const content = chunk.choices[0]?.delta?.content || '';
        if (content) {
          process.stdout.write(content);
          fullText += content;
          
          // ä¿å­˜åˆ°æ–‡ä»¶
          if (this.config.saveToFile) {
            appendFileSync(this.config.qaOutputFile, content);
          }
        }
      }

      if (this.config.logToConsole && !controller.isInterrupted()) console.log('\n'); // æµç»“æŸåæ·»åŠ æ¢è¡Œ
      return fullText;
    } catch (error) {
      if (error.name === 'AbortError') {
        throw error; // é‡æ–°æŠ›å‡ºä¸­æ–­é”™è¯¯
      }
      throw new Error(`Deepseek API error: ${error.message}`);
    }
  }
}

class AudioTranscriber {
  constructor(config) {
    this.config = config;
    this.deepgramClient = null;
    this.deepgramConnection = null;
    this.ffmpegProcess = null;
    this.fileStream = null;
    this.isRunning = false;
    this.aiManager = new AIManager(config);
  }

  initDeepgram() {
    this.deepgramClient = createClient(this.config.deepgramApiKey);
    console.log('âœ… Deepgram client initialized');
  }

  createDeepgramConnection() {
    this.deepgramConnection = this.deepgramClient.listen.live({
      language: this.config.language,
      model: this.config.model,
      smart_format: this.config.smartFormat,
      punctuate: this.config.punctuate,
      encoding: 'linear16',
      sample_rate: 16000,
      channels: 1
    });

    this.deepgramConnection.on(LiveTranscriptionEvents.Open, () => {
      console.log('âœ… Deepgram connection opened');
      console.log('ğŸ™ï¸  Listening to audio...');
    });

    this.deepgramConnection.on(LiveTranscriptionEvents.Transcript, async (data) => {
      const transcript = data.channel.alternatives[0].transcript;
      if (transcript && transcript.trim().length > 0) {
        const timestamp = new Date().toISOString();
        const output = `[${timestamp}] ${transcript}\n`;

        // è¾“å‡ºåˆ°æ§åˆ¶å°
        if (this.config.logToConsole) {
          console.log(`${transcript}`);
        }

        // ä¿å­˜åˆ°æ–‡ä»¶
        if (this.config.saveToFile && this.fileStream) {
          this.fileStream.write(output);
        }

        // æŠŠæ–‡æœ¬ç‰‡æ®µæ¨ç»™ AI managerï¼ˆæµå¼/å¢é‡ï¼‰
        try {
          await this.aiManager.pushTranscriptFragment(transcript);
        } catch (e) {
          console.error('âš ï¸ AI push error:', e.message || e);
        }
      }
    });

    this.deepgramConnection.on(LiveTranscriptionEvents.Metadata, (data) => {
      console.log('ğŸ“Š Metadata:', data);
    });

    this.deepgramConnection.on(LiveTranscriptionEvents.Error, (error) => {
      console.error('âŒ Deepgram error:', error);
    });

    this.deepgramConnection.on(LiveTranscriptionEvents.Close, () => {
      console.log('âš ï¸  Deepgram connection closed');
    });

    console.log('âœ… Deepgram connection created');
  }

  startFFmpegCapture() {
    const ffmpegArgs = [
      '-f', 'avfoundation',
      '-i', `:${this.config.audioDevice}`,
      '-acodec', 'pcm_s16le',
      '-ar', '16000',
      '-ac', '1',
      '-f', 's16le',
      '-'
    ];

    console.log('ğŸš€ Starting FFmpeg audio capture...');
    console.log(`ğŸ“¡ Audio device: ${this.config.audioDevice}`);

    this.ffmpegProcess = spawn('ffmpeg', ffmpegArgs);

    this.ffmpegProcess.stdout.on('data', (audioData) => {
      if (this.deepgramConnection && this.isRunning) {
        this.deepgramConnection.send(audioData);
      }
    });

    this.ffmpegProcess.stderr.on('data', (data) => {
      const message = data.toString();
      if (message.includes('Error') || message.includes('error')) {
        console.error('âš ï¸  FFmpeg:', message);
      }
    });

    this.ffmpegProcess.on('exit', (code) => {
      console.log(`âš ï¸  FFmpeg process exited with code ${code}`);
      this.stop();
    });

    console.log('âœ… FFmpeg capture started');
  }

  createFileStream() {
    if (this.config.saveToFile) {
      this.fileStream = createWriteStream(this.config.outputFile, { flags: 'a' });
      const timestamp = new Date().toISOString();
      this.fileStream.write(`\n\n=== Transcription Session Started: ${timestamp} ===\n\n`);
      console.log(`âœ… Saving transcripts to: ${this.config.outputFile}`);
    }
  }

  async start() {
    if (this.isRunning) {
      console.log('âš ï¸  Transcription is already running');
      return;
    }

    console.log('\nğŸ¯ Starting Audio to Text Transcriber...');
    console.log('='.repeat(50));

    try {
      this.isRunning = true;

      // åˆå§‹åŒ–ç»„ä»¶
      this.initDeepgram();
      this.createDeepgramConnection();
      this.createFileStream();
      this.startFFmpegCapture();

      console.log('='.repeat(50));
      console.log('âœ… Transcription service started successfully!');
      console.log(`ğŸ¤– AI Provider: ${this.config.aiProvider.toUpperCase()}`);
      if (this.config.allowInterruption) {
        console.log(`âš¡ ä¸­æ–­åŠŸèƒ½å·²å¯ç”¨: åœ¨ AI å›ç­”æ—¶è¯´è¯å¯ä»¥æ‰“æ–­ AI`);
      }
      console.log('Press Ctrl+C to stop\n');

    } catch (error) {
      console.error('âŒ Failed to start transcription service:', error);
      this.stop();
    }
  }

  stop() {
    if (!this.isRunning) return;

    console.log('\nâ¹ï¸  Stopping transcription service...');
    this.isRunning = false;

    if (this.ffmpegProcess) {
      this.ffmpegProcess.kill('SIGTERM');
      this.ffmpegProcess = null;
      console.log('âœ… FFmpeg process stopped');
    }

    if (this.deepgramConnection) {
      // finish() might be async; call safely
      try {
        this.deepgramConnection.finish();
      } catch (e) {}
      this.deepgramConnection = null;
      console.log('âœ… Deepgram connection closed');
    }

    if (this.fileStream) {
      const timestamp = new Date().toISOString();
      this.fileStream.write(`\n=== Transcription Session Ended: ${timestamp} ===\n`);
      this.fileStream.end();
      this.fileStream = null;
      console.log('âœ… Output file closed');
    }

    console.log('ğŸ‘‹ Transcription service stopped\n');
  }
}

// åˆ›å»ºè½¬å½•å™¨å®ä¾‹
const transcriber = new AudioTranscriber(CONFIG);

// ä¼˜é›…é€€å‡ºå¤„ç†
process.on('SIGINT', () => {
  console.log('\n\nâš ï¸  Received interrupt signal...');
  transcriber.stop();
  process.exit(0);
});

process.on('SIGTERM', () => {
  transcriber.stop();
  process.exit(0);
});

// å¯åŠ¨æœåŠ¡
transcriber.start();