// éŸ³é¢‘è½¬å½•å™¨æ¨¡å—
import { spawn } from 'child_process';
import { createWriteStream, mkdirSync } from 'fs';
import { dirname } from 'path';
import { createClient, LiveTranscriptionEvents } from '@deepgram/sdk';
import AIManager from '../ai/ai-manager.js';

class AudioTranscriber {
  constructor(config) {
    this.config = config;
    this.deepgramClient = null;
    this.deepgramConnection = null;
    this.ffmpegProcess = null;
    this.fileStream = null;
    this.isRunning = false;
    this.aiManager = new AIManager(config);
  }

  initDeepgram() {
    this.deepgramClient = createClient(this.config.deepgram.apiKey);
    console.log('âœ… Deepgram client initialized');
  }

  createDeepgramConnection() {
    this.deepgramConnection = this.deepgramClient.listen.live({
      language: this.config.deepgram.language,
      model: this.config.deepgram.model,
      smart_format: this.config.deepgram.smartFormat,
      punctuate: this.config.deepgram.punctuate,
      encoding: this.config.audio.encoding,
      sample_rate: this.config.audio.sampleRate,
      channels: this.config.audio.channels
    });

    this.deepgramConnection.on(LiveTranscriptionEvents.Open, () => {
      console.log('âœ… Deepgram connection opened');
      console.log('ğŸ™ï¸  Listening to audio...');
    });

    this.deepgramConnection.on(LiveTranscriptionEvents.Transcript, async (data) => {
      const transcript = data.channel.alternatives[0].transcript;
      if (transcript && transcript.trim().length > 0) {
        const timestamp = new Date().toISOString();
        const output = `[${timestamp}] ${transcript}\n`;

        // è¾“å‡ºåˆ°æ§åˆ¶å°
        if (this.config.output.logToConsole) {
          console.log(`${transcript}`);
        }

        // ä¿å­˜åˆ°æ–‡ä»¶
        if (this.config.output.saveToFile && this.fileStream) {
          this.fileStream.write(output);
        }

        // æŠŠæ–‡æœ¬ç‰‡æ®µæ¨ç»™ AI managerï¼ˆæµå¼/å¢é‡ï¼‰
        try {
          await this.aiManager.pushTranscriptFragment(transcript);
        } catch (e) {
          console.error('âš ï¸ AI push error:', e.message || e);
        }
      }
    });

    this.deepgramConnection.on(LiveTranscriptionEvents.Metadata, (data) => {
      console.log('ğŸ“Š Metadata:', data);
    });

    this.deepgramConnection.on(LiveTranscriptionEvents.Error, (error) => {
      console.error('âŒ Deepgram error:', error);
    });

    this.deepgramConnection.on(LiveTranscriptionEvents.Close, () => {
      console.log('âš ï¸  Deepgram connection closed');
    });

    console.log('âœ… Deepgram connection created');
  }

  startFFmpegCapture() {
    const ffmpegArgs = [
      '-f', 'avfoundation',
      '-i', `:${this.config.audio.device}`,
      '-acodec', 'pcm_s16le',
      '-ar', '16000',
      '-ac', '1',
      '-f', 's16le',
      '-'
    ];

    console.log('ğŸš€ Starting FFmpeg audio capture...');
    console.log(`ğŸ“¡ Audio device: ${this.config.audio.device}`);

    this.ffmpegProcess = spawn('ffmpeg', ffmpegArgs);

    this.ffmpegProcess.stdout.on('data', (audioData) => {
      if (this.deepgramConnection && this.isRunning) {
        this.deepgramConnection.send(audioData);
      }
    });

    this.ffmpegProcess.stderr.on('data', (data) => {
      const message = data.toString();
      if (message.includes('Error') || message.includes('error')) {
        console.error('âš ï¸  FFmpeg:', message);
      }
    });

    this.ffmpegProcess.on('exit', (code) => {
      console.log(`âš ï¸  FFmpeg process exited with code ${code}`);
      this.stop();
    });

    console.log('âœ… FFmpeg capture started');
  }

  createFileStream() {
    if (this.config.output.saveToFile) {
      this.fileStream = createWriteStream(this.config.output.transcriptFile, { flags: 'a' });
      const timestamp = new Date().toISOString();
      this.fileStream.write(`\n\n=== Transcription Session Started: ${timestamp} ===\n\n`);
      console.log(`âœ… Saving transcripts to: ${this.config.output.transcriptFile}`);
    }
  }

  async start() {
    if (this.isRunning) {
      console.log('âš ï¸  Transcription is already running');
      return;
    }

    console.log('\nğŸ¯ Starting Audio to Text Transcriber...');
    console.log('='.repeat(50));

    try {
      this.isRunning = true;

      // åˆ›å»ºè¾“å‡ºç›®å½•
      if (this.config.output.saveToFile) {
        mkdirSync(dirname(this.config.output.transcriptFile), { recursive: true });
        mkdirSync(dirname(this.config.output.qaOutputFile), { recursive: true });
      }

      // åˆå§‹åŒ–ç»„ä»¶
      this.initDeepgram();
      this.createDeepgramConnection();
      this.createFileStream();
      this.startFFmpegCapture();

      console.log('='.repeat(50));
      console.log('âœ… Transcription service started successfully!');
      console.log(`ğŸ¤– AI Provider: ${this.config.ai.provider.toUpperCase()}`);
      if (this.config.interruption.enabled) {
        console.log(`âš¡ ä¸­æ–­åŠŸèƒ½å·²å¯ç”¨: åœ¨ AI å›ç­”æ—¶è¯´è¯å¯ä»¥æ‰“æ–­ AI`);
      }
      console.log('Press Ctrl+C to stop\n');

    } catch (error) {
      console.error('âŒ Failed to start transcription service:', error);
      this.stop();
    }
  }

  stop() {
    if (!this.isRunning) return;

    console.log('\nâ¹ï¸  Stopping transcription service...');
    this.isRunning = false;

    if (this.ffmpegProcess) {
      this.ffmpegProcess.kill('SIGTERM');
      this.ffmpegProcess = null;
      console.log('âœ… FFmpeg process stopped');
    }

    if (this.deepgramConnection) {
      // finish() might be async; call safely
      try {
        this.deepgramConnection.finish();
      } catch (e) {}
      this.deepgramConnection = null;
      console.log('âœ… Deepgram connection closed');
    }

    if (this.fileStream) {
      const timestamp = new Date().toISOString();
      this.fileStream.write(`\n=== Transcription Session Ended: ${timestamp} ===\n`);
      this.fileStream.end();
      this.fileStream = null;
      console.log('âœ… Output file closed');
    }

    console.log('ğŸ‘‹ Transcription service stopped\n');
  }
}

export default AudioTranscriber;