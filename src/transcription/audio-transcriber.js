// éŸ³é¢‘è½¬å½•å™¨æ¨¡å—
import { spawn } from 'child_process';
import { createWriteStream, mkdirSync } from 'fs';
import { dirname } from 'path';
import { createClient, LiveTranscriptionEvents } from '@deepgram/sdk';
import AIManager from '../ai/ai-manager.js';

class AudioTranscriber {
  constructor(config) {
    this.config = config;
    this.deepgramClient = null;
    this.deepgramConnection = null;
    this.ffmpegProcess = null;
    this.fileStream = null;
    this.isRunning = false;
    this.aiManager = new AIManager(config);
    this.lastTranscriptTime = Date.now(); // è·Ÿè¸ªæœ€åä¸€æ¬¡æ”¶åˆ°è½¬å½•çš„æ—¶é—´
    this.audioDetected = false; // éŸ³é¢‘æ£€æµ‹çŠ¶æ€
  }

  initDeepgram() {
    this.deepgramClient = createClient(this.config.deepgram.apiKey);
    console.log('âœ… Deepgram client initialized');
  }

  createDeepgramConnection() {
    this.deepgramConnection = this.deepgramClient.listen.live({
      language: this.config.deepgram.language,
      model: this.config.deepgram.model,
      smart_format: this.config.deepgram.smartFormat,
      punctuate: this.config.deepgram.punctuate,
      encoding: this.config.audio.encoding,
      sample_rate: this.config.audio.sampleRate,
      channels: this.config.audio.channels,
      interim_results: true, // å¯ç”¨ä¸­é—´ç»“æœä»¥æ›´å¿«åœ°æ£€æµ‹éŸ³é¢‘
      vad_turnoff: 500 // è¯­éŸ³æ´»åŠ¨æ£€æµ‹è¶…æ—¶ï¼ˆæ¯«ç§’ï¼‰
    });

    this.deepgramConnection.on(LiveTranscriptionEvents.Open, () => {
      console.log('âœ… Deepgram connection opened');
      console.log('ğŸ™ï¸  Listening to audio...');
    });

    this.deepgramConnection.on(LiveTranscriptionEvents.Transcript, async (data) => {
      // éŸ³é¢‘æ´»åŠ¨çŠ¶æ€ç›‘æ§
      this.lastTranscriptTime = Date.now();
      if (!this.audioDetected) {
        this.audioDetected = true;
        // å¦‚æœæ˜¯ä»é™é»˜çŠ¶æ€åˆ‡æ¢åˆ°æœ‰éŸ³é¢‘è¾“å…¥ï¼Œå¹¶ä¸”AIæ­£åœ¨å›ç­”ï¼Œç«‹å³æç¤ºæ£€æµ‹åˆ°è¯­éŸ³
        if (this.aiManager.isProcessing && this.config.interruption.enabled) {
          console.log('ğŸ”Š æ£€æµ‹åˆ°è¯­éŸ³è¾“å…¥ï¼Œå‡†å¤‡ä¸­æ–­AIå›ç­”...');
        }
      }

      const transcript = data.channel.alternatives[0].transcript;
      if (transcript && transcript.trim().length > 0) {
        const timestamp = new Date().toISOString();
        const output = `[${timestamp}] ${transcript}\n`;

        // è¾“å‡ºåˆ°æ§åˆ¶å°
        if (this.config.output.logToConsole) {
          // å¦‚æœAIæ­£åœ¨å›ç­”ä¸”å¯ç”¨äº†ä¸­æ–­ï¼Œä½¿ç”¨ç‰¹æ®Šæ ‡è®°ä½¿ä¸­æ–­æ›´æ˜æ˜¾
          if (this.aiManager.isProcessing && this.config.interruption.enabled) {
            console.log(`ğŸ”´ ${transcript} ğŸ”´`);
          } else {
            console.log(`${transcript}`);
          }
        }

        // ä¿å­˜åˆ°æ–‡ä»¶
        if (this.config.output.saveToFile && this.fileStream) {
          this.fileStream.write(output);
        }

        // æŠŠæ–‡æœ¬ç‰‡æ®µæ¨ç»™ AI managerï¼ˆæµå¼/å¢é‡ï¼‰
        try {
          await this.aiManager.pushTranscriptFragment(transcript);
        } catch (e) {
          console.error('âš ï¸ AI push error:', e.message || e);
        }
      }
    });

    this.deepgramConnection.on(LiveTranscriptionEvents.Metadata, (data) => {
      // å¯ä»¥ç›‘å¬é™é»˜æ£€æµ‹
      if (data?.speech?.final && !data?.speech?.speech_final) {
        this.audioDetected = false;
      }
    });

    this.deepgramConnection.on(LiveTranscriptionEvents.Error, (error) => {
      console.error('âŒ Deepgram error:', error);
    });

    this.deepgramConnection.on(LiveTranscriptionEvents.Close, () => {
      console.log('âš ï¸  Deepgram connection closed');
    });

    console.log('âœ… Deepgram connection created');
  }

  startFFmpegCapture() {
    const ffmpegArgs = [
      '-f', 'avfoundation',
      '-i', `:${this.config.audio.device}`,
      '-acodec', 'pcm_s16le',
      '-ar', '16000',
      '-ac', '1',
      '-f', 's16le',
      '-'
    ];

    console.log('ğŸš€ Starting FFmpeg audio capture...');
    console.log(`ğŸ“¡ Audio device: ${this.config.audio.device}`);

    this.ffmpegProcess = spawn('ffmpeg', ffmpegArgs);

    this.ffmpegProcess.stdout.on('data', (audioData) => {
      if (this.deepgramConnection && this.isRunning) {
        this.deepgramConnection.send(audioData);
      }
    });

    this.ffmpegProcess.stderr.on('data', (data) => {
      const message = data.toString();
      if (message.includes('Error') || message.includes('error')) {
        console.error('âš ï¸  FFmpeg:', message);
      }
    });

    this.ffmpegProcess.on('exit', (code) => {
      console.log(`âš ï¸  FFmpeg process exited with code ${code}`);
      this.stop();
    });

    console.log('âœ… FFmpeg capture started');
  }

  createFileStream() {
    if (this.config.output.saveToFile) {
      mkdirSync(dirname(this.config.output.transcriptFile), { recursive: true });
      this.fileStream = createWriteStream(this.config.output.transcriptFile, { flags: 'a' });
      const timestamp = new Date().toISOString();
      this.fileStream.write(`\n\n=== Transcription Session Started: ${timestamp} ===\n\n`);
      console.log(`âœ… Saving transcripts to: ${this.config.output.transcriptFile}`);
    }
  }

  async start() {
    if (this.isRunning) {
      console.log('âš ï¸  Transcription is already running');
      return;
    }

    console.log('\nğŸ¯ Starting Audio to Text Transcriber...');
    console.log('='.repeat(50));

    try {
      this.isRunning = true;

      // åˆ›å»ºè¾“å‡ºç›®å½•
      if (this.config.output.saveToFile) {
        mkdirSync(dirname(this.config.output.transcriptFile), { recursive: true });
        mkdirSync(dirname(this.config.output.qaOutputFile), { recursive: true });
      }

      // åˆå§‹åŒ–ç»„ä»¶
      this.initDeepgram();
      this.createDeepgramConnection();
      this.createFileStream();
      this.startFFmpegCapture();

      // å¯åŠ¨éŸ³é¢‘æ´»åŠ¨ç›‘æ§
      this.startAudioMonitoring();

      console.log('='.repeat(50));
      console.log('âœ… Transcription service started successfully!');
      console.log(`ğŸ¤– AI Provider: ${this.config.ai.provider.toUpperCase()}`);
      if (this.config.interruption.enabled) {
        console.log(`âš¡ å¢å¼ºä¸­æ–­åŠŸèƒ½å·²å¯ç”¨: åœ¨AIå›ç­”æ—¶ä¸€æ£€æµ‹åˆ°å£°éŸ³å°±ä¼šç«‹å³ä¸­æ–­`);
      }
      console.log('Press Ctrl+C to stop\n');

    } catch (error) {
      console.error('âŒ Failed to start transcription service:', error);
      this.stop();
    }
  }

  // å¯åŠ¨éŸ³é¢‘æ´»åŠ¨ç›‘æ§
  startAudioMonitoring() {
    // å®šæœŸæ£€æŸ¥éŸ³é¢‘æ´»åŠ¨çŠ¶æ€ï¼Œè¶…è¿‡ä¸€å®šæ—¶é—´æ²¡æœ‰æ¥æ”¶åˆ°éŸ³é¢‘è½¬å½•ï¼Œåˆ™è®¤ä¸ºæ²¡æœ‰äººè¯´è¯
    setInterval(() => {
      const silenceTime = Date.now() - this.lastTranscriptTime;
      // å¦‚æœè¶…è¿‡500msæ²¡æœ‰æ”¶åˆ°éŸ³é¢‘è¾“å…¥ï¼Œå°†çŠ¶æ€é‡ç½®ä¸ºæ— éŸ³é¢‘
      if (silenceTime > 500 && this.audioDetected) {
        this.audioDetected = false;
      }
    }, 200); // æ¯200msæ£€æŸ¥ä¸€æ¬¡éŸ³é¢‘æ´»åŠ¨çŠ¶æ€
  }

  stop() {
    if (!this.isRunning) return;

    console.log('\nâ¹ï¸  Stopping transcription service...');
    this.isRunning = false;

    if (this.ffmpegProcess) {
      this.ffmpegProcess.kill('SIGTERM');
      this.ffmpegProcess = null;
      console.log('âœ… FFmpeg process stopped');
    }

    if (this.deepgramConnection) {
      // finish() might be async; call safely
      try {
        this.deepgramConnection.finish();
      } catch (e) {}
      this.deepgramConnection = null;
      console.log('âœ… Deepgram connection closed');
    }

    if (this.fileStream) {
      const timestamp = new Date().toISOString();
      this.fileStream.write(`\n=== Transcription Session Ended: ${timestamp} ===\n`);
      this.fileStream.end();
      this.fileStream = null;
      console.log('âœ… Output file closed');
    }

    console.log('ğŸ‘‹ Transcription service stopped\n');
  }
}

export default AudioTranscriber;