// éŸ³é¢‘è½¬å½•å™¨æ¨¡å—
import { spawn } from 'child_process';
import { createWriteStream, mkdirSync } from 'fs';
import { dirname } from 'path';
import { createClient, LiveTranscriptionEvents } from '@deepgram/sdk';
import AIManager from '../ai/ai-manager.js';

class AudioTranscriber {
  constructor(config) {
    this.config = config;
    this.deepgramClient = null;
    this.deepgramConnection = null;
    this.ffmpegProcess = null;
    this.fileStream = null;
    this.isRunning = false;
    this.aiManager = new AIManager(config);
    this.lastTranscriptTime = Date.now(); // è·Ÿè¸ªæœ€åä¸€æ¬¡æ”¶åˆ°è½¬å½•çš„æ—¶é—´
    this.audioDetected = false; // éŸ³é¢‘æ£€æµ‹çŠ¶æ€
  }

  initDeepgram() {
    this.deepgramClient = createClient(this.config.deepgram.apiKey);
    console.log('âœ… Deepgram client initialized');
  }

  createDeepgramConnection() {
    this.deepgramConnection = this.deepgramClient.listen.live({
      language: this.config.deepgram.language,
      model: this.config.deepgram.model,
      smart_format: this.config.deepgram.smartFormat,
      punctuate: this.config.deepgram.punctuate,
      encoding: this.config.audio.encoding,
      sample_rate: this.config.audio.sampleRate,
      channels: this.config.audio.channels,
      interim_results: this.config.deepgram.interimResults, // å¯ç”¨ä¸­é—´ç»“æœä»¥æ›´å¿«åœ°æ£€æµ‹éŸ³é¢‘
      vad_turnoff: this.config.deepgram.vadTurnoff // è¯­éŸ³æ´»åŠ¨æ£€æµ‹è¶…æ—¶ï¼ˆæ¯«ç§’ï¼‰
    });

    this.deepgramConnection.on(LiveTranscriptionEvents.Open, () => {
      console.log('âœ… Deepgram connection opened');
      console.log('ğŸ™ï¸  Listening to audio...');
    });

    this.deepgramConnection.on(LiveTranscriptionEvents.Transcript, async (data) => {
      // éŸ³é¢‘æ´»åŠ¨çŠ¶æ€ç›‘æ§
      this.lastTranscriptTime = Date.now();
      
      // æ£€æµ‹åˆ°æ–°éŸ³é¢‘è¾“å…¥
      if (!this.audioDetected) {
        this.audioDetected = true;
        // æ³¨æ„ï¼šç§»é™¤äº†åŸºäºéŸ³é¢‘çš„å³æ—¶ä¸­æ–­åŠŸèƒ½
      }

      const transcript = data.channel.alternatives[0].transcript;
      if (transcript && transcript.trim().length > 0) {
        const timestamp = new Date().toISOString();
        const output = `[${timestamp}] ${transcript}\n`;

        // è¾“å‡ºåˆ°æ§åˆ¶å°
        if (this.config.output.logToConsole) {
          console.log(`${transcript}`);
        }

        // ä¿å­˜åˆ°æ–‡ä»¶
        if (this.config.output.saveToFile && this.fileStream) {
          this.fileStream.write(output);
        }

        // æŠŠæ–‡æœ¬ç‰‡æ®µæ¨ç»™ AI managerï¼ˆæµå¼/å¢é‡ï¼‰
        try {
          await this.aiManager.pushTranscriptFragment(transcript);
        } catch (e) {
          console.error('âš ï¸ AI push error:', e.message || e);
        }
      }
    });

    // ç›‘å¬å…ƒæ•°æ®äº‹ä»¶ä»¥è·å–è¯­éŸ³æ´»åŠ¨çŠ¶æ€
    this.deepgramConnection.on(LiveTranscriptionEvents.Metadata, (data) => {
      // å¦‚æœæ£€æµ‹åˆ°è¯­éŸ³æ®µç»“æŸ
      if (data?.speech?.final && !data?.speech?.speech_final) {
        this.audioDetected = false;
      }
    });

    this.deepgramConnection.on(LiveTranscriptionEvents.Error, (error) => {
      console.error('âŒ Deepgram error:', error);
    });

    this.deepgramConnection.on(LiveTranscriptionEvents.Close, () => {
      console.log('âš ï¸  Deepgram connection closed');
    });

    console.log('âœ… Deepgram connection created');
  }

  startFFmpegCapture() {
    const ffmpegArgs = [
      '-f', 'avfoundation',
      '-i', `:${this.config.audio.device}`,
      '-acodec', 'pcm_s16le',
      '-ar', '16000',
      '-ac', '1',
      '-f', 's16le',
      '-'
    ];

    console.log('ğŸš€ Starting FFmpeg audio capture...');
    console.log(`ğŸ“¡ Audio device: ${this.config.audio.device}`);

    this.ffmpegProcess = spawn('ffmpeg', ffmpegArgs);

    this.ffmpegProcess.stdout.on('data', (audioData) => {
      if (this.deepgramConnection && this.isRunning) {
        this.deepgramConnection.send(audioData);
      }
    });

    this.ffmpegProcess.stderr.on('data', (data) => {
      const message = data.toString();
      if (message.includes('Error') || message.includes('error')) {
        console.error('âš ï¸  FFmpeg:', message);
      }
    });

    this.ffmpegProcess.on('exit', (code) => {
      console.log(`âš ï¸  FFmpeg process exited with code ${code}`);
      this.stop();
    });

    console.log('âœ… FFmpeg capture started');
  }

  createFileStream() {
    if (this.config.output.saveToFile) {
      mkdirSync(dirname(this.config.output.transcriptFile), { recursive: true });
      this.fileStream = createWriteStream(this.config.output.transcriptFile, { flags: 'a' });
      const timestamp = new Date().toISOString();
      this.fileStream.write(`\n\n=== Transcription Session Started: ${timestamp} ===\n\n`);
      console.log(`âœ… Saving transcripts to: ${this.config.output.transcriptFile}`);
    }
  }

  async start() {
    if (this.isRunning) {
      console.log('âš ï¸  Transcription is already running');
      return;
    }

    console.log('\nğŸ¯ Starting Audio to Text Transcriber...');
    console.log('='.repeat(50));

    try {
      this.isRunning = true;

      // åˆ›å»ºè¾“å‡ºç›®å½•
      if (this.config.output.saveToFile) {
        mkdirSync(dirname(this.config.output.transcriptFile), { recursive: true });
        mkdirSync(dirname(this.config.output.qaOutputFile), { recursive: true });
      }

      // åˆå§‹åŒ–AIç®¡ç†å™¨ï¼ˆåŒ…æ‹¬TTSåˆå§‹åŒ–å’Œé”®ç›˜ç›‘å¬åˆå§‹åŒ–ï¼‰
      await this.aiManager.initialize();

      // åˆå§‹åŒ–ç»„ä»¶
      this.initDeepgram();
      this.createDeepgramConnection();
      this.createFileStream();
      this.startFFmpegCapture();

      // å¯åŠ¨éŸ³é¢‘æ´»åŠ¨ç›‘æ§
      if (this.config.audio.activityDetection.enabled) {
        this.startAudioMonitoring();
      }

      console.log('='.repeat(50));
      console.log('âœ… Transcription service started successfully!');
      console.log(`ğŸ¤– AI Provider: ${this.config.ai.provider.toUpperCase()}`);
      
      // TTSåŠŸèƒ½è¯´æ˜
      if (this.config.tts.enabled) {
        console.log(`ğŸ”Š TTS Provider: ${this.config.tts.provider.toUpperCase()}`);
        if (this.config.tts.interruptTtsOnUserInput) {
          console.log(`âš¡ TTSä¸­æ–­åŠŸèƒ½å·²å¯ç”¨: åœ¨TTSæ’­æ”¾æ—¶è¯´è¯ä¼šç«‹å³åœæ­¢å½“å‰æ’­æ”¾`);
        }
      }
      
      // ä¸­æ–­åŠŸèƒ½è¯´æ˜
      console.log(`âš¡ é”®ç›˜ä¸­æ–­åŠŸèƒ½å·²å¯ç”¨: åœ¨AIå›ç­”æ—¶æŒ‰ä¸‹ Ctrl+T å¯ç«‹å³ä¸­æ–­å½“å‰å›ç­”`);
      
      console.log('Press Ctrl+C to stop\n');

    } catch (error) {
      console.error('âŒ Failed to start transcription service:', error);
      this.stop();
    }
  }

  // å¯åŠ¨éŸ³é¢‘æ´»åŠ¨ç›‘æ§
  startAudioMonitoring() {
    // å®šæœŸæ£€æŸ¥éŸ³é¢‘æ´»åŠ¨çŠ¶æ€
    setInterval(() => {
      const silenceTime = Date.now() - this.lastTranscriptTime;
      // å¦‚æœè¶…è¿‡é…ç½®çš„é™é»˜é˜ˆå€¼æ²¡æœ‰æ”¶åˆ°éŸ³é¢‘è¾“å…¥ï¼Œå°†çŠ¶æ€é‡ç½®ä¸ºæ— éŸ³é¢‘
      if (silenceTime > this.config.audio.activityDetection.silenceThresholdMs && this.audioDetected) {
        this.audioDetected = false;
      }
    }, this.config.audio.activityDetection.checkIntervalMs);
  }

  stop() {
    if (!this.isRunning) return;

    console.log('\nâ¹ï¸  Stopping transcription service...');
    this.isRunning = false;

    // æ¸…ç†AIç®¡ç†å™¨èµ„æºï¼ˆåŒ…æ‹¬TTSå’Œé”®ç›˜ç›‘å¬ï¼‰
    this.aiManager.cleanup();
    console.log('âœ… AI manager cleaned up');

    if (this.ffmpegProcess) {
      this.ffmpegProcess.kill('SIGTERM');
      this.ffmpegProcess = null;
      console.log('âœ… FFmpeg process stopped');
    }

    if (this.deepgramConnection) {
      // finish() might be async; call safely
      try {
        this.deepgramConnection.finish();
      } catch (e) {}
      this.deepgramConnection = null;
      console.log('âœ… Deepgram connection closed');
    }

    if (this.fileStream) {
      const timestamp = new Date().toISOString();
      this.fileStream.write(`\n=== Transcription Session Ended: ${timestamp} ===\n`);
      this.fileStream.end();
      this.fileStream = null;
      console.log('âœ… Output file closed');
    }

    console.log('ğŸ‘‹ Transcription service stopped\n');
  }
}

export default AudioTranscriber;